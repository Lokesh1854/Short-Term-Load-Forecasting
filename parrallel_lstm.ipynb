{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+f2FmobaMDLCoc6iyfkD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokesh1854/Short-Term-Load-Forecasting/blob/main/parrallel_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVeLfSHfeCaB",
        "outputId": "13cd8d4a-6280-47b7-a9da-8091caf36d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "tRZGj0GteIJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, concatenate, Dense\n",
        "\n",
        "# Define input shape\n",
        "input_shape = (48,1)  # Assuming timesteps and features are predefined\n",
        "\n",
        "# Define the first LSTM branch\n",
        "input_layer = Input(shape=(48,1))\n",
        "lstm_1 = LSTM(100)(input_layer)\n",
        "lstm_2 = Dense(64, activation = 'relu')(lstm_1)\n",
        "lstm_3 = Dense(32, activation = 'relu')(lstm_2)\n",
        "lstm_4 = Dense(16, activation = 'relu')(lstm_3)\n",
        "lstm_5 = Dense(1, activation = 'relu')(lstm_4)\n",
        "# Define the second LSTM branch\n",
        "lstm_11 = LSTM(100)(input_layer)\n",
        "lstm_21 = Dense(64, activation = 'relu')(lstm_11)\n",
        "lstm_31 = Dense(32, activation = 'relu')(lstm_21)\n",
        "lstm_41 = Dense(16, activation = 'relu')(lstm_31)\n",
        "lstm_51 = Dense(1, activation = 'relu')(lstm_41)\n",
        "# Concatenate the outputs of both LSTM branches\n",
        "merged = concatenate([lstm_5, lstm_51])\n",
        "\n",
        "# Add further layers if needed\n",
        "# Example:\n",
        "output_layer = Dense(1, activation='relu')(merged)\n",
        "\n",
        "\n",
        "# Create the model\n",
        "model1 = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='mape')\n",
        "\n",
        "# Print model summary\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuvSb5g4eKT8",
        "outputId": "49a0eb7b-cd61-4617-beb3-2f53aee9d5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 1)]              0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, 100)                  40800     ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 100)                  40800     ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   6464      ['lstm[0][0]']                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   6464      ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 32)                   2080      ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 32)                   2080      ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 16)                   528       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_6 (Dense)             (None, 16)                   528       ['dense_5[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 1)                    17        ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 1)                    17        ['dense_6[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 2)                    0         ['dense_3[0][0]',             \n",
            "                                                                     'dense_7[0][0]']             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 1)                    3         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99781 (389.77 KB)\n",
            "Trainable params: 99781 (389.77 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating time_steps of 1 day -- 24 x 6\n",
        "look_back = 2*24\n",
        "\n",
        "def prepare_lstm_data(data,look_back):\n",
        "  X_lstm,Y_lstm = [],[]\n",
        "  for i in range(len(data)-look_back):\n",
        "    X_lstm.append(np.array(data.iloc[i:i+look_back,-1]))\n",
        "    Y_lstm.append(np.array(data.iloc[i+look_back,-1]))\n",
        "  return np.array(X_lstm),np.array(Y_lstm)\n"
      ],
      "metadata": {
        "id": "uhr2vJrfgQBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "mz8mMT4Igfqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_path = \"/content/drive/MyDrive/STLF/DataSet/Cluster 0\"\n",
        "\n",
        "mape_err = []\n",
        "\n",
        "for csvFile in os.listdir(cluster_path):\n",
        "  csvPath = os.path.join(cluster_path,csvFile)\n",
        "  df = pd.read_csv(csvPath)\n",
        "\n",
        "  X_lstm,Y_lstm = prepare_lstm_data(df,look_back)\n",
        "  X_lstm_train, X_lstm_test, Y_lstm_train, Y_lstm_test = train_test_split(X_lstm, Y_lstm, test_size=0.1)\n",
        "  model1.fit(X_lstm_train, Y_lstm_train, epochs=25, validation_split=0.1, batch_size=32)\n",
        "\n",
        "  mape_err.append([csvFile,model1.evaluate(X_lstm_test,Y_lstm_test)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztc_ezZUggvb",
        "outputId": "c4e26c4d-0522-482a-cecd-88bb7ba5af6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "531/531 [==============================] - 44s 72ms/step - loss: 13.4451 - val_loss: 10.0494\n",
            "Epoch 2/25\n",
            "531/531 [==============================] - 32s 60ms/step - loss: 9.9391 - val_loss: 9.8329\n",
            "Epoch 3/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 9.4261 - val_loss: 8.9596\n",
            "Epoch 4/25\n",
            "531/531 [==============================] - 33s 62ms/step - loss: 9.2998 - val_loss: 9.3876\n",
            "Epoch 5/25\n",
            "531/531 [==============================] - 36s 67ms/step - loss: 9.1356 - val_loss: 8.8517\n",
            "Epoch 6/25\n",
            "531/531 [==============================] - 35s 67ms/step - loss: 9.1108 - val_loss: 8.7941\n",
            "Epoch 7/25\n",
            "531/531 [==============================] - 33s 63ms/step - loss: 9.0978 - val_loss: 8.9008\n",
            "Epoch 8/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 9.0347 - val_loss: 8.7601\n",
            "Epoch 9/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 8.9812 - val_loss: 9.2324\n",
            "Epoch 10/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 8.9941 - val_loss: 8.6962\n",
            "Epoch 11/25\n",
            "531/531 [==============================] - 34s 64ms/step - loss: 8.9077 - val_loss: 9.0052\n",
            "Epoch 12/25\n",
            "531/531 [==============================] - 34s 64ms/step - loss: 8.9109 - val_loss: 8.7129\n",
            "Epoch 13/25\n",
            "531/531 [==============================] - 35s 66ms/step - loss: 8.9283 - val_loss: 9.6236\n",
            "Epoch 14/25\n",
            "531/531 [==============================] - 33s 63ms/step - loss: 8.9695 - val_loss: 8.6927\n",
            "Epoch 15/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 8.8501 - val_loss: 8.8734\n",
            "Epoch 16/25\n",
            "531/531 [==============================] - 34s 64ms/step - loss: 8.8775 - val_loss: 8.7996\n",
            "Epoch 17/25\n",
            "531/531 [==============================] - 33s 62ms/step - loss: 8.8794 - val_loss: 9.1792\n",
            "Epoch 18/25\n",
            "531/531 [==============================] - 32s 60ms/step - loss: 8.8470 - val_loss: 8.9732\n",
            "Epoch 19/25\n",
            "531/531 [==============================] - 33s 61ms/step - loss: 8.8628 - val_loss: 8.8036\n",
            "Epoch 20/25\n",
            "531/531 [==============================] - 33s 62ms/step - loss: 8.8111 - val_loss: 8.8764\n",
            "Epoch 21/25\n",
            "531/531 [==============================] - 36s 69ms/step - loss: 8.8204 - val_loss: 8.6548\n",
            "Epoch 22/25\n",
            "531/531 [==============================] - 33s 62ms/step - loss: 8.8390 - val_loss: 8.7746\n",
            "Epoch 23/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 8.7650 - val_loss: 8.6137\n",
            "Epoch 24/25\n",
            "531/531 [==============================] - 32s 61ms/step - loss: 8.7516 - val_loss: 8.6869\n",
            "Epoch 25/25\n",
            "531/531 [==============================] - 32s 60ms/step - loss: 8.7568 - val_loss: 8.6295\n",
            "66/66 [==============================] - 2s 15ms/step - loss: 8.4778\n",
            "Epoch 1/25\n",
            "468/468 [==============================] - 27s 58ms/step - loss: 11.3943 - val_loss: 10.9433\n",
            "Epoch 2/25\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 11.0943 - val_loss: 11.2662\n",
            "Epoch 3/25\n",
            "468/468 [==============================] - 30s 64ms/step - loss: 11.1117 - val_loss: 11.4177\n",
            "Epoch 4/25\n",
            "468/468 [==============================] - 29s 63ms/step - loss: 10.9952 - val_loss: 10.9281\n",
            "Epoch 5/25\n",
            "468/468 [==============================] - 30s 65ms/step - loss: 10.9022 - val_loss: 10.7729\n",
            "Epoch 6/25\n",
            "468/468 [==============================] - 29s 63ms/step - loss: 10.9282 - val_loss: 10.8229\n",
            "Epoch 7/25\n",
            "468/468 [==============================] - 30s 64ms/step - loss: 10.9130 - val_loss: 10.7086\n",
            "Epoch 8/25\n",
            "468/468 [==============================] - 29s 63ms/step - loss: 10.9038 - val_loss: 10.8951\n",
            "Epoch 9/25\n",
            "468/468 [==============================] - 31s 67ms/step - loss: 10.9042 - val_loss: 10.7205\n",
            "Epoch 10/25\n",
            "468/468 [==============================] - 31s 65ms/step - loss: 10.8524 - val_loss: 10.9405\n",
            "Epoch 11/25\n",
            "468/468 [==============================] - 31s 66ms/step - loss: 10.8468 - val_loss: 10.8517\n",
            "Epoch 12/25\n",
            "468/468 [==============================] - 31s 67ms/step - loss: 10.7587 - val_loss: 10.8717\n",
            "Epoch 13/25\n",
            "468/468 [==============================] - 30s 65ms/step - loss: 10.8380 - val_loss: 10.7157\n",
            "Epoch 14/25\n",
            "468/468 [==============================] - 31s 66ms/step - loss: 10.7314 - val_loss: 10.6960\n",
            "Epoch 15/25\n",
            "468/468 [==============================] - 31s 66ms/step - loss: 10.7118 - val_loss: 10.6324\n",
            "Epoch 16/25\n",
            "468/468 [==============================] - 31s 67ms/step - loss: 10.7358 - val_loss: 11.2697\n",
            "Epoch 17/25\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 10.7167 - val_loss: 10.7776\n",
            "Epoch 18/25\n",
            "468/468 [==============================] - 30s 63ms/step - loss: 10.6388 - val_loss: 10.5688\n",
            "Epoch 19/25\n",
            "468/468 [==============================] - 30s 63ms/step - loss: 10.7134 - val_loss: 10.6760\n",
            "Epoch 20/25\n",
            "468/468 [==============================] - 27s 58ms/step - loss: 10.6278 - val_loss: 11.1809\n",
            "Epoch 21/25\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 10.5906 - val_loss: 10.8074\n",
            "Epoch 22/25\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 10.5921 - val_loss: 10.6579\n",
            "Epoch 23/25\n",
            "468/468 [==============================] - 30s 63ms/step - loss: 10.5460 - val_loss: 10.5777\n",
            "Epoch 24/25\n",
            "468/468 [==============================] - 30s 65ms/step - loss: 10.5364 - val_loss: 10.8692\n",
            "Epoch 25/25\n",
            "468/468 [==============================] - 29s 62ms/step - loss: 10.5662 - val_loss: 10.5171\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 10.4783\n",
            "Epoch 1/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.5931 - val_loss: 8.0927\n",
            "Epoch 2/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.4121 - val_loss: 8.4330\n",
            "Epoch 3/25\n",
            "474/474 [==============================] - 29s 62ms/step - loss: 8.3825 - val_loss: 8.1124\n",
            "Epoch 4/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.3469 - val_loss: 8.5667\n",
            "Epoch 5/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.3741 - val_loss: 8.0720\n",
            "Epoch 6/25\n",
            "474/474 [==============================] - 31s 65ms/step - loss: 8.2798 - val_loss: 8.0747\n",
            "Epoch 7/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.3202 - val_loss: 7.9824\n",
            "Epoch 8/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.3054 - val_loss: 7.9924\n",
            "Epoch 9/25\n",
            "474/474 [==============================] - 30s 64ms/step - loss: 8.2142 - val_loss: 8.0458\n",
            "Epoch 10/25\n",
            "474/474 [==============================] - 37s 77ms/step - loss: 8.2480 - val_loss: 8.1890\n",
            "Epoch 11/25\n",
            "474/474 [==============================] - 35s 73ms/step - loss: 8.2226 - val_loss: 8.0431\n",
            "Epoch 12/25\n",
            "474/474 [==============================] - 34s 72ms/step - loss: 8.2193 - val_loss: 8.0731\n",
            "Epoch 13/25\n",
            "474/474 [==============================] - 31s 65ms/step - loss: 8.2434 - val_loss: 7.9608\n",
            "Epoch 14/25\n",
            "474/474 [==============================] - 29s 61ms/step - loss: 8.2673 - val_loss: 8.1009\n",
            "Epoch 15/25\n",
            "474/474 [==============================] - 29s 61ms/step - loss: 8.2294 - val_loss: 8.1617\n",
            "Epoch 16/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.1962 - val_loss: 8.1656\n",
            "Epoch 17/25\n",
            "474/474 [==============================] - 30s 64ms/step - loss: 8.1768 - val_loss: 8.0511\n",
            "Epoch 18/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.1711 - val_loss: 8.0032\n",
            "Epoch 19/25\n",
            "474/474 [==============================] - 30s 63ms/step - loss: 8.1619 - val_loss: 8.0989\n",
            "Epoch 20/25\n",
            "474/474 [==============================] - 31s 66ms/step - loss: 8.1310 - val_loss: 8.0887\n",
            "Epoch 21/25\n",
            "474/474 [==============================] - 32s 68ms/step - loss: 8.1185 - val_loss: 8.0153\n",
            "Epoch 22/25\n",
            "474/474 [==============================] - 32s 67ms/step - loss: 8.1206 - val_loss: 8.0670\n",
            "Epoch 23/25\n",
            "474/474 [==============================] - 31s 66ms/step - loss: 8.1416 - val_loss: 8.4296\n",
            "Epoch 24/25\n",
            "474/474 [==============================] - 31s 65ms/step - loss: 8.1173 - val_loss: 7.9787\n",
            "Epoch 25/25\n",
            "474/474 [==============================] - 32s 67ms/step - loss: 8.1142 - val_loss: 7.9928\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 8.0675\n",
            "Epoch 1/25\n",
            "485/485 [==============================] - 32s 65ms/step - loss: 8.3344 - val_loss: 8.1818\n",
            "Epoch 2/25\n",
            "485/485 [==============================] - 35s 72ms/step - loss: 8.2534 - val_loss: 8.1240\n",
            "Epoch 3/25\n",
            "485/485 [==============================] - 33s 67ms/step - loss: 8.1935 - val_loss: 8.5260\n",
            "Epoch 4/25\n",
            "485/485 [==============================] - 32s 66ms/step - loss: 8.1221 - val_loss: 8.0944\n",
            "Epoch 5/25\n",
            "485/485 [==============================] - 32s 67ms/step - loss: 8.1301 - val_loss: 8.0868\n",
            "Epoch 6/25\n",
            "485/485 [==============================] - 33s 68ms/step - loss: 8.1266 - val_loss: 8.1463\n",
            "Epoch 7/25\n",
            "485/485 [==============================] - 32s 65ms/step - loss: 8.0716 - val_loss: 8.1733\n",
            "Epoch 8/25\n",
            "485/485 [==============================] - 33s 69ms/step - loss: 8.0888 - val_loss: 8.2167\n",
            "Epoch 9/25\n",
            "485/485 [==============================] - 31s 64ms/step - loss: 8.0840 - val_loss: 8.2689\n",
            "Epoch 10/25\n",
            "485/485 [==============================] - 32s 66ms/step - loss: 8.0914 - val_loss: 8.1848\n",
            "Epoch 11/25\n",
            "485/485 [==============================] - 33s 68ms/step - loss: 8.0369 - val_loss: 8.0748\n",
            "Epoch 12/25\n",
            "485/485 [==============================] - 32s 66ms/step - loss: 8.0714 - val_loss: 7.9918\n",
            "Epoch 13/25\n",
            "485/485 [==============================] - 32s 65ms/step - loss: 8.0246 - val_loss: 8.0267\n",
            "Epoch 14/25\n",
            "416/485 [========================>.....] - ETA: 4s - loss: 8.0177"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mape_err"
      ],
      "metadata": {
        "id": "aaTsPMhVp3J1",
        "outputId": "631472ed-eb41-4d6c-9e79-76490cf23145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['block_16.csv', 8.47779369354248],\n",
              " ['block_27.csv', 10.478328704833984],\n",
              " ['block_4.csv', 8.067485809326172],\n",
              " ['block_9.csv', 8.116782188415527]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(cluster_path)"
      ],
      "metadata": {
        "id": "tDB8ZWPvp-Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save('lstm_parallel')"
      ],
      "metadata": {
        "id": "JCrEMxVqqCep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}