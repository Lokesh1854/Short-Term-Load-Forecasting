{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lokesh1854/Short-Term-Load-Forecasting/blob/main/pre_processing_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDfHGvMXmMkN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVRQ4h-slQP_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Define the Google Drive URL\n",
        "url_weather = 'https://drive.google.com/uc?id=1I0jZHTrrLqMCO3XUJ0AoeLrvSMNhpKI3&export=download'\n",
        "url_block0 = 'https://drive.google.com/uc?id=1ZceSLxN-d0BY32vDQ7jGw8svhLmQwCnW&export=download'\n",
        "\n",
        "# Fetch the content of the file\n",
        "response_weather = requests.get(url_weather)\n",
        "\n",
        "# Create a StringIO object to read the content as a file-like object\n",
        "csv_content_weather = StringIO(response_weather.text)\n",
        "\n",
        "# Read the CSV content using pd.read_csv()\n",
        "dfw = pd.read_csv(csv_content_weather)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmCQrHXanNIY"
      },
      "outputs": [],
      "source": [
        "# Fetch the content of the file\n",
        "response_block0 = requests.get(url_block0)\n",
        "\n",
        "# Create a StringIO object to read the content as a file-like object\n",
        "csv_content_block0 = StringIO(response_block0.text)\n",
        "\n",
        "# Read the CSV content using pd.read_csv()\n",
        "dfb0 = pd.read_csv(csv_content_block0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4GgBWfRqHXV"
      },
      "outputs": [],
      "source": [
        "dfw[\"time\"] = pd.to_datetime(dfw[\"time\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRogRprH_LCO"
      },
      "outputs": [],
      "source": [
        "dfw.set_index('time', inplace=True)\n",
        "\n",
        "# Sort the DataFrame by the index (which is the 'time' column)\n",
        "dfws = dfw.sort_values(by='time')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu6rnvEpZZOv"
      },
      "outputs": [],
      "source": [
        "datetime_index = dfws.index\n",
        "\n",
        "# Generate a new index with intermediate timestamps between each existing entry\n",
        "new_index = []\n",
        "for i in range(len(datetime_index) - 1):\n",
        "  current_time = datetime_index[i]\n",
        "  next_time = datetime_index[i + 1]\n",
        "  time_delta = pd.Timedelta(minutes=30)\n",
        "  # Create a datetime object halfway between current and next time\n",
        "  intermediate_time = current_time + time_delta\n",
        "  # Append current, intermediate, and next time to the new index\n",
        "  new_index.extend([current_time, intermediate_time])\n",
        "# Add the last time from the original index\n",
        "new_index.append(datetime_index[-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_index_df = pd.DataFrame({'timestamp': new_index})\n",
        "\n",
        "# Left join dfws with new_index_df\n",
        "merged_df = pd.merge(new_index_df, dfws, left_on='timestamp', right_index=True, how='left')\n",
        "\n",
        "# If you want to fill missing values with NaN\n",
        "merged_df.fillna(value=np.nan, inplace=True)\n"
      ],
      "metadata": {
        "id": "9CZJ_Tpz6AU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['precipType', 'icon', 'summary']\n",
        "cleaned_df = merged_df.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "_5ZSMpDh7eKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpolated_df = cleaned_df.interpolate(method='linear', axis=0, limit_direction='both')"
      ],
      "metadata": {
        "id": "273-98Eu7v6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzOnp3G8dYO-"
      },
      "outputs": [],
      "source": [
        "n_unique = dfb0['LCLid'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LS_RLfDfm__"
      },
      "outputs": [],
      "source": [
        "dfb0[\"tstp\"] = pd.to_datetime(dfb0[\"tstp\"])\n",
        "dfb0[\"date\"] = dfb0[\"tstp\"].dt.date\n",
        "dfb0[\"time\"] = dfb0[\"tstp\"].dt.time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DssB1G5iIDG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_start_indices(df):\n",
        "  \"\"\"\n",
        "  This function takes a DataFrame containing an 'LCLid' column and returns a dictionary\n",
        "  where keys are unique LCLids and values are their first indices in the DataFrame.\n",
        "  \"\"\"\n",
        "\n",
        "  # Assuming the column name is 'LCLid'\n",
        "  # Adjust the column name if it differs in your DataFrame\n",
        "  unique_lclids = df['LCLid'].unique()  # Get unique LCLids\n",
        "\n",
        "  # Initialize an empty dictionary to store results\n",
        "  start_indices = {}\n",
        "\n",
        "  # Iterate through unique LCLids and find their first indices\n",
        "  for lclid in unique_lclids:\n",
        "    start_index = df[df['LCLid'] == lclid].index[0]  # Find first index for each LCLid\n",
        "    start_indices[lclid] = start_index\n",
        "\n",
        "  return start_indices\n",
        "\n",
        "# Get the dictionary with starting indices for each LCLid\n",
        "start_indices = get_start_indices(dfb0.copy())  # Avoid modifying original DataFrame\n",
        "\n",
        "# Print the results\n",
        "# for lclid, start_index in start_indices.items():\n",
        "#   print(f\"LCLid: {lclid}, Starting Index: {start_index}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yRUhwZNlyE8"
      },
      "outputs": [],
      "source": [
        "arr=[]\n",
        "arr1 = []\n",
        "for value in start_indices.values():\n",
        "  arr.append(value)\n",
        "for i in range(len(arr)-1):\n",
        "  arr1.append(arr[i+1]-1)\n",
        "# for i in range(len(arr)-1):\n",
        "#   print(arr[i],\" \",arr1[i])\n",
        "# print(len(arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kS9bVbjyjU4Y"
      },
      "outputs": [],
      "source": [
        "startdate=[]\n",
        "enddate=[]\n",
        "indices = []\n",
        "for i in range(len(arr)-1):\n",
        "  #print(arr[i],\" \",dfb0.date[arr[i]],\" \",dfb0.date[arr[i+1]-1])\n",
        "  indices.append(arr[i])\n",
        "  startdate.append(dfb0.date[arr[i]])\n",
        "  enddate.append(dfb0.date[arr[i+1]-1])\n",
        "# print(arr[len(arr)-1],\" \",dfb0.date[len(arr)-1],\" \",dfb0.date[len(dfb0)-1])\n",
        "# print(max(startdate))\n",
        "# print(min(enddate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW57cL39qBkL"
      },
      "outputs": [],
      "source": [
        "startdatec=startdate.copy()\n",
        "enddatec=enddate.copy()\n",
        "from datetime import timedelta\n",
        "startdatec.sort(reverse=True)\n",
        "enddatec.sort()\n",
        "days = enddatec[0]-startdatec[0]\n",
        "i = 0\n",
        "delta = timedelta(days=365, hours=0, minutes=0, seconds=0)\n",
        "while(days<delta):\n",
        "  i = i+1\n",
        "  days = abs(enddatec[i]-startdatec[i])\n",
        "  #print(days)\n",
        "\n",
        "# print(i)\n",
        "# print(abs(startdatec[i]-enddatec[i]))\n",
        "# print(startdatec[i])\n",
        "# print(enddatec[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SMHVf9vYPe"
      },
      "outputs": [],
      "source": [
        "dfb0c = dfb0.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrO8WSC2Dh4T",
        "outputId": "e6165d06-3120-4eba-a076-450544bba96c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "print(i)\n",
        "p = 0\n",
        "z = 0\n",
        "y = 0\n",
        "j = 0\n",
        "##for j in range(n_unique-1):\n",
        "z = arr[j]\n",
        "y = arr1[j]-arr[j]\n",
        "#print(y)\n",
        "#print(dfb0c.date[y])\n",
        "p = arr[j]\n",
        "while(p<=arr1[j] and dfb0c.date[z]<startdatec[i]):\n",
        "  z = z+1\n",
        "while(p<=arr1[j] and dfb0c.date[y]>enddatec[i]):\n",
        "  y = y-1\n",
        "# print(y)\n",
        "# print(dfb0c.date[y])\n",
        "#print(z,\" \",dfb0c.date[z],\" \",y,\" \",dfb0c.date[y])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCL6XUK7y1jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3d658f-bc1d-4345-f3a4-bb56ae2a726f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "print(i)\n",
        "p = 0\n",
        "z = 0\n",
        "y = 0\n",
        "arrz=[]\n",
        "arry=[]\n",
        "for j in range(n_unique-1):\n",
        "  z = arr[j]\n",
        "  y = arr1[j]\n",
        "  p = arr[j]\n",
        "  while(p<=arr1[j] and dfb0c.date[z]<startdatec[i]):\n",
        "    z = z+1\n",
        "  while(p<=arr1[j] and dfb0c.date[y]>enddatec[i]):\n",
        "    y = y-1\n",
        "  arrz.append(z)\n",
        "  arry.append(y)\n",
        "  #print(z,\" \",dfb0c.date[z],\" \",y,\" \",dfb0c.date[y])\n",
        "  #print(z,\" \",y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined=[]\n",
        "c=0\n",
        "while(c<len(arrz)):\n",
        "  combined.append(arrz[c])\n",
        "  combined.append(arry[c])\n",
        "  c=c+1"
      ],
      "metadata": {
        "id": "qaHr2jMS3I5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_year = 12*30*24*2\n",
        "threshold = one_year\n",
        "def get_intersection(data, indices):\n",
        "  result = []\n",
        "  for i in range(0, len(indices), 2):\n",
        "    start_index = combined[i]\n",
        "    end_index = combined[i + 1]+1\n",
        "    slice_data = data[start_index:end_index]\n",
        "    row_count = len(slice_data)\n",
        "    if(row_count>threshold):\n",
        "      result.append(slice_data)\n",
        "  return pd.concat(result, ignore_index=True)\n",
        "intersected_data = get_intersection(dfb0c, combined)\n",
        "\n",
        "\n",
        "num_unique=intersected_data['LCLid'].nunique()\n",
        "#num_unique\n"
      ],
      "metadata": {
        "id": "_Gqu_ULz3hl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power_data = intersected_data\n",
        "#power_data"
      ],
      "metadata": {
        "id": "R-TwUC_uAlcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_data = interpolated_df\n",
        "#weather_data"
      ],
      "metadata": {
        "id": "u9KqcYREAsW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merged_data = pd.merge(weather_data, power_data, left_on='timestamp', right_on='tstp', how='left')\n",
        "\n",
        "# Reset the index to default integer index\n",
        "merged_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "pivoted_data = merged_data.pivot(index=['timestamp', 'visibility', 'windBearing', 'temperature', 'dewPoint', 'pressure', 'apparentTemperature', 'windSpeed', 'humidity'], columns='LCLid', values='energy(kWh/hh)')\n",
        "\n",
        "# Reset the index to default integer index\n",
        "pivoted_data.reset_index(inplace=True)\n",
        "\n",
        "if np.nan in pivoted_data.columns:\n",
        "  pivoted_data.drop(columns=[np.nan], inplace=True)\n",
        "#pivoted_data\n"
      ],
      "metadata": {
        "id": "LstApYhfFa5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.to_datetime(startdatec[i])\n",
        "end_date = pd.to_datetime(enddatec[i])+pd.Timedelta(days=1)\n",
        "\n",
        "# Convert timestamp column to datetime if it's not already in datetime format\n",
        "pivoted_data['timestamp'] = pd.to_datetime(pivoted_data['timestamp'])\n",
        "\n",
        "# Filter the DataFrame based on the date range\n",
        "filtered_data = pivoted_data[(pivoted_data['timestamp'] >= start_date) & (pivoted_data['timestamp'] < end_date)]\n",
        "\n",
        "# Reset index\n",
        "filtered_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#filtered_data"
      ],
      "metadata": {
        "id": "Fsnw3nBLL1ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_values = filtered_data.median()\n",
        "filtered_data.fillna(median_values, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQnrBHvqNUj0",
        "outputId": "9a79c9ed-8f1c-41d4-f00a-47d2cbb7727d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-39e8391c3d31>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data.fillna(median_values, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smart_meter_columns = filtered_data.columns[9:]\n",
        "filtered_data[smart_meter_columns] = filtered_data[smart_meter_columns].astype(float)\n",
        "filtered_data['PowerConsumption'] = filtered_data[smart_meter_columns].sum(axis=1)\n",
        "filtered_data = filtered_data.drop(smart_meter_columns, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lapcazCHY05c",
        "outputId": "a60a5601-b83a-4ada-e49c-f83c07a4177b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-3cdc379bbeb0>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data[smart_meter_columns] = filtered_data[smart_meter_columns].astype(float)\n",
            "<ipython-input-84-3cdc379bbeb0>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_data['PowerConsumption'] = filtered_data[smart_meter_columns].sum(axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = filtered_data.columns[1:9]\n",
        "scaler.fit(filtered_data[numerical_columns])\n",
        "filtered_data[numerical_columns] = scaler.transform(filtered_data[numerical_columns])"
      ],
      "metadata": {
        "id": "1RE_h28tY_5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_data.to_csv('modified_dataset_block0.csv', index = False)"
      ],
      "metadata": {
        "id": "rNAqzLGFpHT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n"
      ],
      "metadata": {
        "id": "sEw95tg-P-Sb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}